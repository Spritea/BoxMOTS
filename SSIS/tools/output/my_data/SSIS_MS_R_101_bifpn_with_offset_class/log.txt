[09/05 22:31:11] detectron2 INFO: Rank of current process: 0. World size: 1
[09/05 22:31:14] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.13 (default, Mar 28 2022, 11:38:47) [GCC 7.5.0]
numpy                   1.23.2
detectron2              0.6 @/home/wensheng/anaconda3/envs/ssis/lib/python3.8/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.1
detectron2 arch flags   3.7, 5.0, 5.2, 6.0, 6.1, 7.0, 7.5, 8.0, 8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.8.1+cu111 @/home/wensheng/anaconda3/envs/ssis/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3,4,5,6,7     NVIDIA A100 80GB PCIe (arch=8.0)
Driver version          470.57.02
CUDA_HOME               /home/wensheng/cuda/cuda-11.1
Pillow                  9.2.0
torchvision             0.9.1+cu111 @/home/wensheng/anaconda3/envs/ssis/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220512
iopath                  0.1.9
cv2                     4.6.0
----------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/05 22:31:14] detectron2 INFO: Command line arguments: Namespace(config_file='../configs/SSIS/MS_R_101_BiFPN_with_offset_class_my_data.yaml', dist_url='tcp://127.0.0.1:50161', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[09/05 22:31:14] detectron2 INFO: Contents of args.config_file=../configs/SSIS/MS_R_101_BiFPN_with_offset_class_my_data.yaml:
_BASE_: "Base-SSIS.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-101.pkl"
  BACKBONE:
    NAME: "build_fcos_resnet_bifpn_backbone"
  RESNETS:
    DEPTH: 101
  FCOS:
    NUM_CLASSES: 2
    OFFSET: True
    CLASS_AWARE: True
  BiFPN:
    IN_FEATURES: ["res3", "res4", "res5"]
    OUT_CHANNELS: 160
    NORM: "SyncBN"
  CONDINST:
    MASK_OUT_STRIDE: 2
    MAX_PROPOSALS: 500
SOLVER:
  STEPS: (40000,)
  MAX_ITER: 45000
  BASE_LR: 0.001
  IMS_PER_BATCH: 2
DATASETS:
  TRAIN: ("kitti_mots_train_in_trainval",)
  TEST: ("kitti_mots_val_in_trainval",)
OUTPUT_DIR: "output/my_data/SSIS_MS_R_101_bifpn_with_offset_class"

[09/05 22:31:14] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - kitti_mots_val_in_trainval
  TRAIN:
  - kitti_mots_train_in_trainval
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    CROP_INSTANCE: true
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  HFLIP_TRAIN: true
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    ANTI_ALIAS: false
    FREEZE_AT: 2
    NAME: build_fcos_resnet_bifpn_backbone
  BASIS_MODULE:
    ANN_SET: coco
    COMMON_STRIDE: 8
    CONVS_DIM: 128
    IN_FEATURES:
    - p3
    - p4
    - p5
    LOSS_ON: false
    LOSS_WEIGHT: 0.3
    NAME: ProtoNet
    NORM: SyncBN
    NUM_BASES: 4
    NUM_CLASSES: 80
    NUM_CONVS: 3
  BATEXT:
    CANONICAL_SIZE: 96
    CONV_DIM: 256
    IN_FEATURES:
    - p2
    - p3
    - p4
    NUM_CHARS: 25
    NUM_CONV: 2
    POOLER_RESOLUTION:
    - 8
    - 32
    POOLER_SCALES:
    - 0.25
    - 0.125
    - 0.0625
    RECOGNITION_LOSS: ctc
    RECOGNIZER: attn
    SAMPLING_RATIO: 1
    VOC_SIZE: 96
  BLENDMASK:
    ATTN_SIZE: 14
    BOTTOM_RESOLUTION: 56
    INSTANCE_LOSS_WEIGHT: 1.0
    POOLER_SAMPLING_RATIO: 1
    POOLER_SCALES:
    - 0.25
    POOLER_TYPE: ROIAlignV2
    TOP_INTERP: bilinear
    VISUALIZE: false
  BiFPN:
    IN_FEATURES:
    - res3
    - res4
    - res5
    NORM: SyncBN
    NUM_REPEATS: 6
    OUT_CHANNELS: 160
  CONDINST:
    MASK_BRANCH:
      CHANNELS: 128
      IN_FEATURES:
      - p3
      - p4
      - p5
      NORM: BN
      NUM_CONVS: 4
      OUT_CHANNELS: 8
      SEMANTIC_LOSS_ON: false
    MASK_HEAD:
      BOUNDARY_LOSS: false
      CHANNELS: 8
      DEFORM_MASKIOU: false
      DISABLE_REL_COORDS: false
      NUM_LAYERS: 3
      USE_FP16: false
    MASK_OUT_STRIDE: 2
    MAX_PROPOSALS: 500
  DEVICE: cuda
  DLA:
    CONV_BODY: DLA34
    NORM: FrozenBN
    OUT_FEATURES:
    - stage2
    - stage3
    - stage4
    - stage5
  FCOS:
    CENTER_SAMPLE: true
    CLASS_AWARE: true
    FPN_STRIDES:
    - 8
    - 16
    - 32
    - 64
    - 128
    INFERENCE_TH_TEST: 0.05
    INFERENCE_TH_TRAIN: 0.05
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    LOC_LOSS_TYPE: giou
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.6
    NORM: GN
    NUM_BOX_CONVS: 4
    NUM_CLASSES: 2
    NUM_CLS_CONVS: 4
    NUM_SHARE_CONVS: 0
    OFFSET: true
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 100
    POS_RADIUS: 1.5
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 1000
    PRIOR_PROB: 0.01
    SIZES_OF_INTEREST:
    - 64
    - 128
    - 256
    - 512
    THRESH_WITH_CTR: true
    TOP_LEVELS: 2
    USE_DEFORMABLE: false
    USE_RELU: true
    USE_SCALE: true
    YIELD_PROPOSAL: false
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  MEInst:
    AGNOSTIC: true
    CENTER_SAMPLE: true
    DIM_MASK: 60
    FLAG_PARAMETERS: false
    FPN_STRIDES:
    - 8
    - 16
    - 32
    - 64
    - 128
    GCN_KERNEL_SIZE: 9
    INFERENCE_TH_TEST: 0.05
    INFERENCE_TH_TRAIN: 0.05
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    LAST_DEFORMABLE: false
    LOC_LOSS_TYPE: giou
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    LOSS_ON_MASK: false
    MASK_LOSS_TYPE: mse
    MASK_ON: true
    MASK_SIZE: 28
    NMS_TH: 0.6
    NORM: GN
    NUM_BOX_CONVS: 4
    NUM_CLASSES: 80
    NUM_CLS_CONVS: 4
    NUM_MASK_CONVS: 4
    NUM_SHARE_CONVS: 0
    PATH_COMPONENTS: datasets/coco/components/coco_2017_train_class_agnosticTrue_whitenTrue_sigmoidTrue_60.npz
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 100
    POS_RADIUS: 1.5
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 1000
    PRIOR_PROB: 0.01
    SIGMOID: true
    SIZES_OF_INTEREST:
    - 64
    - 128
    - 256
    - 512
    THRESH_WITH_CTR: false
    TOP_LEVELS: 2
    TYPE_DEFORMABLE: DCNv1
    USE_DEFORMABLE: false
    USE_GCN_IN_MASK: false
    USE_RELU: true
    USE_SCALE: true
    WHITEN: true
  META_ARCHITECTURE: CondInst
  MOBILENET: false
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FCOS
  RESNETS:
    DEFORM_INTERVAL: 1
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  TOP_MODULE:
    DIM: 16
    NAME: conv
  VOVNET:
    BACKBONE_OUT_CHANNELS: 256
    CONV_BODY: V-39-eSE
    DEFORMABLE_GROUPS: 1
    NORM: FrozenBN
    OUT_CHANNELS: 256
    OUT_FEATURES:
    - stage2
    - stage3
    - stage4
    - stage5
    STAGE_WITH_DCN:
    - false
    - false
    - false
    - false
    WITH_MODULATED_DCN: false
  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-101.pkl
OUTPUT_DIR: output/my_data/SSIS_MS_R_101_bifpn_with_offset_class
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.001
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 45000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  STEPS:
  - 40000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[09/05 22:31:14] detectron2 INFO: Full config saved to output/my_data/SSIS_MS_R_101_bifpn_with_offset_class/config.yaml
[09/05 22:31:14] d2.utils.env INFO: Using a generated random seed 16006897
[09/05 22:31:18] d2.engine.defaults INFO: Model:
CondInst(
  (backbone): BiFPN(
    (bottom_up): BackboneWithTopLevels(
      (backbone): ResNet(
        (stem): BasicStem(
          (conv1): Conv2d(
            3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
        )
        (res2): Sequential(
          (0): BottleneckBlock(
            (shortcut): Conv2d(
              64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv1): Conv2d(
              64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
            (conv2): Conv2d(
              64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
            (conv3): Conv2d(
              64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
          )
          (1): BottleneckBlock(
            (conv1): Conv2d(
              256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
            (conv2): Conv2d(
              64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
            (conv3): Conv2d(
              64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
          )
          (2): BottleneckBlock(
            (conv1): Conv2d(
              256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
            (conv2): Conv2d(
              64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
            (conv3): Conv2d(
              64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
          )
        )
        (res3): Sequential(
          (0): BottleneckBlock(
            (shortcut): Conv2d(
              256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
            )
            (conv1): Conv2d(
              256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
              (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
            )
            (conv2): Conv2d(
              128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
            )
            (conv3): Conv2d(
              128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
            )
          )
          (1): BottleneckBlock(
            (conv1): Conv2d(
              512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
            )
            (conv2): Conv2d(
              128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
            )
            (conv3): Conv2d(
              128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
            )
          )
          (2): BottleneckBlock(
            (conv1): Conv2d(
              512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
            )
            (conv2): Conv2d(
              128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
            )
            (conv3): Conv2d(
              128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
            )
          )
          (3): BottleneckBlock(
            (conv1): Conv2d(
              512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
            )
            (conv2): Conv2d(
              128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
            )
            (conv3): Conv2d(
              128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
            )
          )
        )
        (res4): Sequential(
          (0): BottleneckBlock(
            (shortcut): Conv2d(
              512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
            )
            (conv1): Conv2d(
              512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv2): Conv2d(
              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv3): Conv2d(
              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
            )
          )
          (1): BottleneckBlock(
            (conv1): Conv2d(
              1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv2): Conv2d(
              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv3): Conv2d(
              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
            )
          )
          (2): BottleneckBlock(
            (conv1): Conv2d(
              1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv2): Conv2d(
              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv3): Conv2d(
              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
            )
          )
          (3): BottleneckBlock(
            (conv1): Conv2d(
              1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv2): Conv2d(
              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv3): Conv2d(
              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
            )
          )
          (4): BottleneckBlock(
            (conv1): Conv2d(
              1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv2): Conv2d(
              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv3): Conv2d(
              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
            )
          )
          (5): BottleneckBlock(
            (conv1): Conv2d(
              1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv2): Conv2d(
              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv3): Conv2d(
              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
            )
          )
          (6): BottleneckBlock(
            (conv1): Conv2d(
              1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv2): Conv2d(
              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv3): Conv2d(
              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
            )
          )
          (7): BottleneckBlock(
            (conv1): Conv2d(
              1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv2): Conv2d(
              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv3): Conv2d(
              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
            )
          )
          (8): BottleneckBlock(
            (conv1): Conv2d(
              1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv2): Conv2d(
              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv3): Conv2d(
              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
            )
          )
          (9): BottleneckBlock(
            (conv1): Conv2d(
              1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv2): Conv2d(
              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv3): Conv2d(
              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
            )
          )
          (10): BottleneckBlock(
            (conv1): Conv2d(
              1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv2): Conv2d(
              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv3): Conv2d(
              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
            )
          )
          (11): BottleneckBlock(
            (conv1): Conv2d(
              1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv2): Conv2d(
              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv3): Conv2d(
              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
            )
          )
          (12): BottleneckBlock(
            (conv1): Conv2d(
              1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv2): Conv2d(
              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv3): Conv2d(
              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
            )
          )
          (13): BottleneckBlock(
            (conv1): Conv2d(
              1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv2): Conv2d(
              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv3): Conv2d(
              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
            )
          )
          (14): BottleneckBlock(
            (conv1): Conv2d(
              1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv2): Conv2d(
              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv3): Conv2d(
              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
            )
          )
          (15): BottleneckBlock(
            (conv1): Conv2d(
              1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv2): Conv2d(
              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv3): Conv2d(
              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
            )
          )
          (16): BottleneckBlock(
            (conv1): Conv2d(
              1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv2): Conv2d(
              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv3): Conv2d(
              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
            )
          )
          (17): BottleneckBlock(
            (conv1): Conv2d(
              1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv2): Conv2d(
              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv3): Conv2d(
              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
            )
          )
          (18): BottleneckBlock(
            (conv1): Conv2d(
              1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv2): Conv2d(
              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv3): Conv2d(
              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
            )
          )
          (19): BottleneckBlock(
            (conv1): Conv2d(
              1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv2): Conv2d(
              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv3): Conv2d(
              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
            )
          )
          (20): BottleneckBlock(
            (conv1): Conv2d(
              1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv2): Conv2d(
              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv3): Conv2d(
              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
            )
          )
          (21): BottleneckBlock(
            (conv1): Conv2d(
              1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv2): Conv2d(
              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv3): Conv2d(
              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
            )
          )
          (22): BottleneckBlock(
            (conv1): Conv2d(
              1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv2): Conv2d(
              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv3): Conv2d(
              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
            )
          )
        )
        (res5): Sequential(
          (0): BottleneckBlock(
            (shortcut): Conv2d(
              1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
              (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
            )
            (conv1): Conv2d(
              1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
            )
            (conv2): Conv2d(
              512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
            )
            (conv3): Conv2d(
              512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
            )
          )
          (1): BottleneckBlock(
            (conv1): Conv2d(
              2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
            )
            (conv2): Conv2d(
              512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
            )
            (conv3): Conv2d(
              512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
            )
          )
          (2): BottleneckBlock(
            (conv1): Conv2d(
              2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
            )
            (conv2): Conv2d(
              512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
            )
            (conv3): Conv2d(
              512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
            )
          )
        )
      )
      (res6): FeatureMapResampler(
        (reduction): Conv2d(
          2048, 160, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (res7): FeatureMapResampler()
    )
    (repeated_bifpn): ModuleList(
      (0): SingleBiFPN(
        (outputs_f3_3_4): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (lateral_2_f2): Conv2d(
          2048, 160, kernel_size=(1, 1), stride=(1, 1)
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f2_2_5): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (lateral_1_f1): Conv2d(
          1024, 160, kernel_size=(1, 1), stride=(1, 1)
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f1_1_6): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (lateral_0_f0): Conv2d(
          512, 160, kernel_size=(1, 1), stride=(1, 1)
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f0_0_7): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f1_1_7_8): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f2_2_6_9): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f3_3_5_10): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f4_4_11): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): SingleBiFPN(
        (outputs_f3_3_4): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f2_2_5): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f1_1_6): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f0_0_7): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f1_1_7_8): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f2_2_6_9): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f3_3_5_10): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f4_4_11): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): SingleBiFPN(
        (outputs_f3_3_4): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f2_2_5): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f1_1_6): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f0_0_7): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f1_1_7_8): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f2_2_6_9): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f3_3_5_10): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f4_4_11): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): SingleBiFPN(
        (outputs_f3_3_4): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f2_2_5): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f1_1_6): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f0_0_7): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f1_1_7_8): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f2_2_6_9): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f3_3_5_10): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f4_4_11): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): SingleBiFPN(
        (outputs_f3_3_4): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f2_2_5): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f1_1_6): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f0_0_7): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f1_1_7_8): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f2_2_6_9): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f3_3_5_10): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f4_4_11): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): SingleBiFPN(
        (outputs_f3_3_4): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f2_2_5): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f1_1_6): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f0_0_7): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f1_1_7_8): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f2_2_6_9): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f3_3_5_10): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (outputs_f4_4_11): Conv2d(
          160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (proposal_generator): FCOS(
    (fcos_head): FCOSHead(
      (cls_tower): Sequential(
        (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): GroupNorm(32, 160, eps=1e-05, affine=True)
        (2): ReLU()
        (3): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): GroupNorm(32, 160, eps=1e-05, affine=True)
        (5): ReLU()
        (6): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): GroupNorm(32, 160, eps=1e-05, affine=True)
        (8): ReLU()
        (9): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (10): GroupNorm(32, 160, eps=1e-05, affine=True)
        (11): ReLU()
      )
      (bbox_tower): Sequential(
        (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): GroupNorm(32, 160, eps=1e-05, affine=True)
        (2): ReLU()
        (3): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): GroupNorm(32, 160, eps=1e-05, affine=True)
        (5): ReLU()
        (6): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): GroupNorm(32, 160, eps=1e-05, affine=True)
        (8): ReLU()
        (9): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (10): GroupNorm(32, 160, eps=1e-05, affine=True)
        (11): ReLU()
      )
      (share_tower): Sequential()
      (cls_logits): Conv2d(160, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bbox_pred): Conv2d(160, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (ctrness): Conv2d(160, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (offset_pred): Conv2d(160, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
    )
    (fcos_outputs): FCOSOutputs(
      (loc_loss_func): IOULoss()
    )
  )
  (mask_head): DynamicMaskHead()
  (mask_branch): MaskBranch(
    (refine): ModuleList(
      (0): Sequential(
        (0): Conv2d(160, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): Sequential(
        (0): Conv2d(160, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (2): Sequential(
        (0): Conv2d(160, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
    )
    (tower): Sequential(
      (0): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (2): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (3): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (4): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (controller): Conv2d(160, 169, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (controller2): Conv2d(160, 169, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)
[09/05 22:31:18] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-101.pkl ...
[09/05 22:31:18] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[09/05 22:31:18] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up.backbone:
| Names in Model    | Names in Checkpoint       | Shapes                                          |
|:------------------|:--------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}   | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}   | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}   | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.10.conv1.*   | res4_10_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.10.conv2.*   | res4_10_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.10.conv3.*   | res4_10_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.11.conv1.*   | res4_11_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.11.conv2.*   | res4_11_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.11.conv3.*   | res4_11_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.12.conv1.*   | res4_12_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.12.conv2.*   | res4_12_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.12.conv3.*   | res4_12_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.13.conv1.*   | res4_13_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.13.conv2.*   | res4_13_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.13.conv3.*   | res4_13_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.14.conv1.*   | res4_14_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.14.conv2.*   | res4_14_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.14.conv3.*   | res4_14_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.15.conv1.*   | res4_15_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.15.conv2.*   | res4_15_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.15.conv3.*   | res4_15_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.16.conv1.*   | res4_16_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.16.conv2.*   | res4_16_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.16.conv3.*   | res4_16_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.17.conv1.*   | res4_17_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.17.conv2.*   | res4_17_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.17.conv3.*   | res4_17_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.18.conv1.*   | res4_18_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.18.conv2.*   | res4_18_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.18.conv3.*   | res4_18_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.19.conv1.*   | res4_19_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.19.conv2.*   | res4_19_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.19.conv3.*   | res4_19_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.20.conv1.*   | res4_20_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.20.conv2.*   | res4_20_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.20.conv3.*   | res4_20_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.21.conv1.*   | res4_21_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.21.conv2.*   | res4_21_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.21.conv3.*   | res4_21_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.22.conv1.*   | res4_22_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.22.conv2.*   | res4_22_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.22.conv3.*   | res4_22_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.6.conv1.*    | res4_6_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.6.conv2.*    | res4_6_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.6.conv3.*    | res4_6_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.7.conv1.*    | res4_7_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.7.conv2.*    | res4_7_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.7.conv3.*    | res4_7_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.8.conv1.*    | res4_8_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.8.conv2.*    | res4_8_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.8.conv3.*    | res4_8_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.9.conv1.*    | res4_9_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.9.conv2.*    | res4_9_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.9.conv3.*    | res4_9_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}   | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*            | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                   | (64, 3, 7, 7)                                   |
[09/05 22:31:18] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.bottom_up.res6.reduction.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.bottom_up.res6.reduction.weight[0m
[34mbackbone.repeated_bifpn.0.lateral_0_f0.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.0.lateral_0_f0.{bias, weight}[0m
[34mbackbone.repeated_bifpn.0.lateral_1_f1.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.0.lateral_1_f1.{bias, weight}[0m
[34mbackbone.repeated_bifpn.0.lateral_2_f2.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.0.lateral_2_f2.{bias, weight}[0m
[34mbackbone.repeated_bifpn.0.outputs_f0_0_7.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.0.outputs_f0_0_7.weight[0m
[34mbackbone.repeated_bifpn.0.outputs_f1_1_6.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.0.outputs_f1_1_6.weight[0m
[34mbackbone.repeated_bifpn.0.outputs_f1_1_7_8.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.0.outputs_f1_1_7_8.weight[0m
[34mbackbone.repeated_bifpn.0.outputs_f2_2_5.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.0.outputs_f2_2_5.weight[0m
[34mbackbone.repeated_bifpn.0.outputs_f2_2_6_9.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.0.outputs_f2_2_6_9.weight[0m
[34mbackbone.repeated_bifpn.0.outputs_f3_3_4.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.0.outputs_f3_3_4.weight[0m
[34mbackbone.repeated_bifpn.0.outputs_f3_3_5_10.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.0.outputs_f3_3_5_10.weight[0m
[34mbackbone.repeated_bifpn.0.outputs_f4_4_11.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.0.outputs_f4_4_11.weight[0m
[34mbackbone.repeated_bifpn.0.{weights_f0_0_7, weights_f1_1_6, weights_f1_1_7_8, weights_f2_2_5, weights_f2_2_6_9, weights_f3_3_4, weights_f3_3_5_10, weights_f4_4_11}[0m
[34mbackbone.repeated_bifpn.1.outputs_f0_0_7.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.1.outputs_f0_0_7.weight[0m
[34mbackbone.repeated_bifpn.1.outputs_f1_1_6.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.1.outputs_f1_1_6.weight[0m
[34mbackbone.repeated_bifpn.1.outputs_f1_1_7_8.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.1.outputs_f1_1_7_8.weight[0m
[34mbackbone.repeated_bifpn.1.outputs_f2_2_5.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.1.outputs_f2_2_5.weight[0m
[34mbackbone.repeated_bifpn.1.outputs_f2_2_6_9.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.1.outputs_f2_2_6_9.weight[0m
[34mbackbone.repeated_bifpn.1.outputs_f3_3_4.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.1.outputs_f3_3_4.weight[0m
[34mbackbone.repeated_bifpn.1.outputs_f3_3_5_10.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.1.outputs_f3_3_5_10.weight[0m
[34mbackbone.repeated_bifpn.1.outputs_f4_4_11.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.1.outputs_f4_4_11.weight[0m
[34mbackbone.repeated_bifpn.1.{weights_f0_0_7, weights_f1_1_6, weights_f1_1_7_8, weights_f2_2_5, weights_f2_2_6_9, weights_f3_3_4, weights_f3_3_5_10, weights_f4_4_11}[0m
[34mbackbone.repeated_bifpn.2.outputs_f0_0_7.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.2.outputs_f0_0_7.weight[0m
[34mbackbone.repeated_bifpn.2.outputs_f1_1_6.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.2.outputs_f1_1_6.weight[0m
[34mbackbone.repeated_bifpn.2.outputs_f1_1_7_8.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.2.outputs_f1_1_7_8.weight[0m
[34mbackbone.repeated_bifpn.2.outputs_f2_2_5.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.2.outputs_f2_2_5.weight[0m
[34mbackbone.repeated_bifpn.2.outputs_f2_2_6_9.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.2.outputs_f2_2_6_9.weight[0m
[34mbackbone.repeated_bifpn.2.outputs_f3_3_4.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.2.outputs_f3_3_4.weight[0m
[34mbackbone.repeated_bifpn.2.outputs_f3_3_5_10.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.2.outputs_f3_3_5_10.weight[0m
[34mbackbone.repeated_bifpn.2.outputs_f4_4_11.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.2.outputs_f4_4_11.weight[0m
[34mbackbone.repeated_bifpn.2.{weights_f0_0_7, weights_f1_1_6, weights_f1_1_7_8, weights_f2_2_5, weights_f2_2_6_9, weights_f3_3_4, weights_f3_3_5_10, weights_f4_4_11}[0m
[34mbackbone.repeated_bifpn.3.outputs_f0_0_7.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.3.outputs_f0_0_7.weight[0m
[34mbackbone.repeated_bifpn.3.outputs_f1_1_6.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.3.outputs_f1_1_6.weight[0m
[34mbackbone.repeated_bifpn.3.outputs_f1_1_7_8.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.3.outputs_f1_1_7_8.weight[0m
[34mbackbone.repeated_bifpn.3.outputs_f2_2_5.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.3.outputs_f2_2_5.weight[0m
[34mbackbone.repeated_bifpn.3.outputs_f2_2_6_9.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.3.outputs_f2_2_6_9.weight[0m
[34mbackbone.repeated_bifpn.3.outputs_f3_3_4.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.3.outputs_f3_3_4.weight[0m
[34mbackbone.repeated_bifpn.3.outputs_f3_3_5_10.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.3.outputs_f3_3_5_10.weight[0m
[34mbackbone.repeated_bifpn.3.outputs_f4_4_11.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.3.outputs_f4_4_11.weight[0m
[34mbackbone.repeated_bifpn.3.{weights_f0_0_7, weights_f1_1_6, weights_f1_1_7_8, weights_f2_2_5, weights_f2_2_6_9, weights_f3_3_4, weights_f3_3_5_10, weights_f4_4_11}[0m
[34mbackbone.repeated_bifpn.4.outputs_f0_0_7.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.4.outputs_f0_0_7.weight[0m
[34mbackbone.repeated_bifpn.4.outputs_f1_1_6.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.4.outputs_f1_1_6.weight[0m
[34mbackbone.repeated_bifpn.4.outputs_f1_1_7_8.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.4.outputs_f1_1_7_8.weight[0m
[34mbackbone.repeated_bifpn.4.outputs_f2_2_5.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.4.outputs_f2_2_5.weight[0m
[34mbackbone.repeated_bifpn.4.outputs_f2_2_6_9.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.4.outputs_f2_2_6_9.weight[0m
[34mbackbone.repeated_bifpn.4.outputs_f3_3_4.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.4.outputs_f3_3_4.weight[0m
[34mbackbone.repeated_bifpn.4.outputs_f3_3_5_10.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.4.outputs_f3_3_5_10.weight[0m
[34mbackbone.repeated_bifpn.4.outputs_f4_4_11.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.4.outputs_f4_4_11.weight[0m
[34mbackbone.repeated_bifpn.4.{weights_f0_0_7, weights_f1_1_6, weights_f1_1_7_8, weights_f2_2_5, weights_f2_2_6_9, weights_f3_3_4, weights_f3_3_5_10, weights_f4_4_11}[0m
[34mbackbone.repeated_bifpn.5.outputs_f0_0_7.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.5.outputs_f0_0_7.weight[0m
[34mbackbone.repeated_bifpn.5.outputs_f1_1_6.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.5.outputs_f1_1_6.weight[0m
[34mbackbone.repeated_bifpn.5.outputs_f1_1_7_8.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.5.outputs_f1_1_7_8.weight[0m
[34mbackbone.repeated_bifpn.5.outputs_f2_2_5.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.5.outputs_f2_2_5.weight[0m
[34mbackbone.repeated_bifpn.5.outputs_f2_2_6_9.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.5.outputs_f2_2_6_9.weight[0m
[34mbackbone.repeated_bifpn.5.outputs_f3_3_4.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.5.outputs_f3_3_4.weight[0m
[34mbackbone.repeated_bifpn.5.outputs_f3_3_5_10.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.5.outputs_f3_3_5_10.weight[0m
[34mbackbone.repeated_bifpn.5.outputs_f4_4_11.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.repeated_bifpn.5.outputs_f4_4_11.weight[0m
[34mbackbone.repeated_bifpn.5.{weights_f0_0_7, weights_f1_1_6, weights_f1_1_7_8, weights_f2_2_5, weights_f2_2_6_9, weights_f3_3_4, weights_f3_3_5_10, weights_f4_4_11}[0m
[34mcontroller.{bias, weight}[0m
[34mcontroller2.{bias, weight}[0m
[34mmask_branch.refine.0.0.weight[0m
[34mmask_branch.refine.0.1.{bias, running_mean, running_var, weight}[0m
[34mmask_branch.refine.1.0.weight[0m
[34mmask_branch.refine.1.1.{bias, running_mean, running_var, weight}[0m
[34mmask_branch.refine.2.0.weight[0m
[34mmask_branch.refine.2.1.{bias, running_mean, running_var, weight}[0m
[34mmask_branch.tower.0.0.weight[0m
[34mmask_branch.tower.0.1.{bias, running_mean, running_var, weight}[0m
[34mmask_branch.tower.1.0.weight[0m
[34mmask_branch.tower.1.1.{bias, running_mean, running_var, weight}[0m
[34mmask_branch.tower.2.0.weight[0m
[34mmask_branch.tower.2.1.{bias, running_mean, running_var, weight}[0m
[34mmask_branch.tower.3.0.weight[0m
[34mmask_branch.tower.3.1.{bias, running_mean, running_var, weight}[0m
[34mmask_branch.tower.4.{bias, weight}[0m
[34mmask_head.{sizes_of_interest, strides}[0m
[34mproposal_generator.fcos_head.bbox_pred.{bias, weight}[0m
[34mproposal_generator.fcos_head.bbox_tower.0.{bias, weight}[0m
[34mproposal_generator.fcos_head.bbox_tower.1.{bias, weight}[0m
[34mproposal_generator.fcos_head.bbox_tower.10.{bias, weight}[0m
[34mproposal_generator.fcos_head.bbox_tower.3.{bias, weight}[0m
[34mproposal_generator.fcos_head.bbox_tower.4.{bias, weight}[0m
[34mproposal_generator.fcos_head.bbox_tower.6.{bias, weight}[0m
[34mproposal_generator.fcos_head.bbox_tower.7.{bias, weight}[0m
[34mproposal_generator.fcos_head.bbox_tower.9.{bias, weight}[0m
[34mproposal_generator.fcos_head.cls_logits.{bias, weight}[0m
[34mproposal_generator.fcos_head.cls_tower.0.{bias, weight}[0m
[34mproposal_generator.fcos_head.cls_tower.1.{bias, weight}[0m
[34mproposal_generator.fcos_head.cls_tower.10.{bias, weight}[0m
[34mproposal_generator.fcos_head.cls_tower.3.{bias, weight}[0m
[34mproposal_generator.fcos_head.cls_tower.4.{bias, weight}[0m
[34mproposal_generator.fcos_head.cls_tower.6.{bias, weight}[0m
[34mproposal_generator.fcos_head.cls_tower.7.{bias, weight}[0m
[34mproposal_generator.fcos_head.cls_tower.9.{bias, weight}[0m
[34mproposal_generator.fcos_head.ctrness.{bias, weight}[0m
[34mproposal_generator.fcos_head.offset_pred.{bias, weight}[0m
[34mproposal_generator.fcos_head.scales.0.scale[0m
[34mproposal_generator.fcos_head.scales.1.scale[0m
[34mproposal_generator.fcos_head.scales.2.scale[0m
[34mproposal_generator.fcos_head.scales.3.scale[0m
[34mproposal_generator.fcos_head.scales.4.scale[0m
[09/05 22:31:18] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
[09/05 22:31:21] adet.data.datasets.soba INFO: Loading ../../my_dataset/KITTI_MOTS/annotations/val_in_trainval_gt_as_coco_instances.json takes 2.94 seconds.
